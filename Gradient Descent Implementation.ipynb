{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOi8ou8c/m0WcKP28XVcgjj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthikeyan-ganesan86/CS/blob/master/Gradient%20Descent%20Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#**************************************************************************#\n",
        "#Import all libraries for using in the program                             # \n",
        "#**************************************************************************#\n",
        "# DESCRIPTION: IMPLEMENTING GRADIENT DESCENT                               #\n",
        "#--------------------------------------------------------------------------#\n",
        "#           Name       BITS ID                                             #\n",
        "#--------------------------------------------------------------------------#\n",
        "#      Karthikeyan G  ***********                                          #\n",
        "#--------------------------------------------------------------------------#\n",
        "############################################################################\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from sympy import *\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#Random Number for n is choosen between 75 and 140                             #\n",
        "################################################################################\n",
        "\n",
        "n = random.randint(75, 140)\n",
        "\n",
        "################################################################################\n",
        "# Deciding 40 %  of n for negative numbers for α rest of which was choosen     #\n",
        "# as Positive                                                                  #\n",
        "################################################################################\n",
        "\n",
        "(n1)= n*.4\n",
        "n1=math.floor(n*(.4))\n",
        "n2=math.floor(n-n1)\n",
        "\n",
        "alpha1=np.random.randint(-100, -1, (n1, 1))\n",
        "#print(alpha1)\n",
        "alpha2=np.random.randint(1, 100, (n2, 1))\n",
        "#print(alpha2)\n",
        "\n",
        "alpha1=alpha1/100\n",
        "alpha2=alpha2/100\n",
        "\n",
        "alpha=np.concatenate([alpha1,alpha2])\n",
        "print(\"Values of Alpha are:\\n\", alpha)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj_eGzbUMggD",
        "outputId": "59f9a870-6fbd-4ec5-f012-c301055b2d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values of Alpha are:\n",
            " [[-0.94]\n",
            " [-0.87]\n",
            " [-0.32]\n",
            " [-0.91]\n",
            " [-0.24]\n",
            " [-0.51]\n",
            " [-0.47]\n",
            " [-0.15]\n",
            " [-0.45]\n",
            " [-0.6 ]\n",
            " [-0.24]\n",
            " [-0.17]\n",
            " [-0.28]\n",
            " [-0.88]\n",
            " [-0.72]\n",
            " [-0.09]\n",
            " [-0.68]\n",
            " [-0.71]\n",
            " [-0.29]\n",
            " [-0.24]\n",
            " [-0.02]\n",
            " [-0.28]\n",
            " [-0.63]\n",
            " [-1.  ]\n",
            " [-0.83]\n",
            " [-0.97]\n",
            " [-0.53]\n",
            " [-0.13]\n",
            " [-0.87]\n",
            " [-0.28]\n",
            " [-0.85]\n",
            " [-0.23]\n",
            " [-0.55]\n",
            " [-0.78]\n",
            " [-0.41]\n",
            " [-0.32]\n",
            " [-0.83]\n",
            " [-0.96]\n",
            " [-1.  ]\n",
            " [-0.32]\n",
            " [-0.52]\n",
            " [-0.39]\n",
            " [-0.86]\n",
            " [-0.68]\n",
            " [-0.98]\n",
            " [-0.36]\n",
            " [-0.83]\n",
            " [-0.19]\n",
            " [-0.9 ]\n",
            " [-0.6 ]\n",
            " [-0.63]\n",
            " [-0.7 ]\n",
            " [-0.61]\n",
            " [-0.47]\n",
            " [ 0.06]\n",
            " [ 0.41]\n",
            " [ 0.65]\n",
            " [ 0.27]\n",
            " [ 0.93]\n",
            " [ 0.14]\n",
            " [ 0.87]\n",
            " [ 0.06]\n",
            " [ 0.53]\n",
            " [ 0.89]\n",
            " [ 0.1 ]\n",
            " [ 0.5 ]\n",
            " [ 0.28]\n",
            " [ 0.23]\n",
            " [ 0.42]\n",
            " [ 0.87]\n",
            " [ 0.7 ]\n",
            " [ 0.83]\n",
            " [ 0.81]\n",
            " [ 0.21]\n",
            " [ 0.86]\n",
            " [ 0.58]\n",
            " [ 0.23]\n",
            " [ 0.98]\n",
            " [ 0.78]\n",
            " [ 0.4 ]\n",
            " [ 0.57]\n",
            " [ 0.08]\n",
            " [ 0.28]\n",
            " [ 0.69]\n",
            " [ 0.4 ]\n",
            " [ 0.22]\n",
            " [ 0.75]\n",
            " [ 0.2 ]\n",
            " [ 0.24]\n",
            " [ 0.79]\n",
            " [ 0.83]\n",
            " [ 0.4 ]\n",
            " [ 0.47]\n",
            " [ 0.28]\n",
            " [ 0.91]\n",
            " [ 0.77]\n",
            " [ 0.34]\n",
            " [ 0.97]\n",
            " [ 0.91]\n",
            " [ 0.57]\n",
            " [ 0.64]\n",
            " [ 0.41]\n",
            " [ 0.09]\n",
            " [ 0.04]\n",
            " [ 0.2 ]\n",
            " [ 0.99]\n",
            " [ 0.62]\n",
            " [ 0.83]\n",
            " [ 0.03]\n",
            " [ 0.02]\n",
            " [ 0.99]\n",
            " [ 0.83]\n",
            " [ 0.47]\n",
            " [ 0.23]\n",
            " [ 0.54]\n",
            " [ 0.26]\n",
            " [ 0.46]\n",
            " [ 0.18]\n",
            " [ 0.5 ]\n",
            " [ 0.65]\n",
            " [ 0.74]\n",
            " [ 0.17]\n",
            " [ 0.46]\n",
            " [ 0.53]\n",
            " [ 0.2 ]\n",
            " [ 0.57]\n",
            " [ 0.99]\n",
            " [ 0.02]\n",
            " [ 0.97]\n",
            " [ 0.88]\n",
            " [ 0.92]\n",
            " [ 0.18]\n",
            " [ 0.86]\n",
            " [ 0.54]\n",
            " [ 0.21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#        INITIAL VALUES FOR VARIABLES TO BE USED IN GRADIENT DESCENT           #\n",
        "################################################################################\n",
        "valX = 1000                     # Initial Value of x is set here\n",
        "iterations = 0                  # Initialize iteration\n",
        "tolerance = 2/100               # Tolerance was set as 2%\n",
        "printData = True                # Helps to exit loop\n",
        "maxIterations = 1000            # Number of Iterations\n",
        "al=alpha                        # α\n",
        "tempvalX=0                      # Temporary Value\n",
        "eta=0.01                        #Learning Rate η\n",
        "\n",
        "\n",
        "print(\"Initial x = \"+str(valX)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "################################################################################\n",
        "# Derivative of (Σ αᵢXᵢ²) is (2 * xᵢ * αᵢ) this is added n times from 1 to n   #\n",
        "# Substituting the value if xᵢ initially as 1000 and αᵢ randomly chosen above  #\n",
        "################################################################################\n",
        "\n",
        "  fn=0\n",
        "  x=[]\n",
        "  \n",
        "  for i in range(0,n):\n",
        "    x.append(valX)\n",
        "    fn=(2*x[i]*al[i]) + fn\n",
        "\n",
        "################################################################################\n",
        "# fn is multiplied by multiplied with learning rate 0.01   #Learning Rate η    #\n",
        "################################################################################\n",
        "\n",
        "  fn = fn * eta\n",
        "\n",
        " \n",
        "#  print(\"tempvalX before\",valX - fn)\n",
        "#  print(\"valX before\",valX)\n",
        "  tempvalX=  math.ceil(valX - fn)\n",
        "# print(\"tempvalX after\",tempvalX)\n",
        "\n",
        "  #If the number of iterations goes out of bounds, maybe valX (and/or valY) is diverging\n",
        "  #Let's stop the loop and try to understand.\n",
        "   \n",
        "  iterations += 1\n",
        "  if iterations > maxIterations:\n",
        "     print(\"Too many iterations. Adjust alpha and make sure that the function is convex!\")\n",
        "     printData = False\n",
        "     break\n",
        "  \n",
        "  #print(\"tempvalX before\",tempvalX)\n",
        "  #tempvalX=(math.ceil(tempvalX))\n",
        "  #print(\"tempvalX after\",tempvalX)\n",
        "  #print(\"valX\",valX)\n",
        "\n",
        "  if abs(tempvalX-valX) < tolerance:\n",
        "    break\n",
        "    \n",
        "  print(\"x = \"+str(tempvalX)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "  #Update the values for next iteration\n",
        "  valX = tempvalX\n",
        "\n",
        "if printData:\n",
        " print(\"The function at value \"+str(fn)+\" converges to a minimum\")\n",
        " print(\"Number of iterations:\",iterations,sep=\" \")\n",
        " print(\"Final x =\",tempvalX,sep=\" \")\n",
        "\n",
        "\n",
        "#print(valX-fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lgn_O9SqdXi",
        "outputId": "45252688-6f9f-4ff4-e95e-1d19dc1b90ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial x = 1000 Iteration = 0\n",
            "x = 776 Iteration = 1\n",
            "x = 603 Iteration = 2\n",
            "x = 468 Iteration = 3\n",
            "x = 364 Iteration = 4\n",
            "x = 283 Iteration = 5\n",
            "x = 220 Iteration = 6\n",
            "x = 171 Iteration = 7\n",
            "x = 133 Iteration = 8\n",
            "x = 104 Iteration = 9\n",
            "x = 81 Iteration = 10\n",
            "x = 63 Iteration = 11\n",
            "x = 49 Iteration = 12\n",
            "x = 39 Iteration = 13\n",
            "x = 31 Iteration = 14\n",
            "x = 25 Iteration = 15\n",
            "x = 20 Iteration = 16\n",
            "x = 16 Iteration = 17\n",
            "x = 13 Iteration = 18\n",
            "x = 11 Iteration = 19\n",
            "x = 9 Iteration = 20\n",
            "x = 7 Iteration = 21\n",
            "x = 6 Iteration = 22\n",
            "x = 5 Iteration = 23\n",
            "x = 4 Iteration = 24\n",
            "The function at value [0.8968] converges to a minimum\n",
            "Number of iterations: 25\n",
            "Final x = 4\n"
          ]
        }
      ]
    }
  ]
}
