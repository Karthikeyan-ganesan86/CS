{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS50v44mgKAQG/9WCRuuG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthikeyan-ganesan86/CS/blob/master/Gradient_Descent_Implementation_Different_X_values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#**************************************************************************#\n",
        "#Import all libraries for using in the program                             # \n",
        "#**************************************************************************#\n",
        "# DESCRIPTION: IMPLEMENTING GRADIENT DESCENT                               #\n",
        "#--------------------------------------------------------------------------#\n",
        "#           Name       BITS ID                                             #\n",
        "#--------------------------------------------------------------------------#\n",
        "#      Karthikeyan G  ***********                                          #\n",
        "#--------------------------------------------------------------------------#\n",
        "############################################################################\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from sympy import *\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "################################################################################\n",
        "#Random Number for n is choosen between 75 and 140                             #\n",
        "################################################################################\n",
        "\n",
        "n = random.randint(75, 140)\n",
        "\n",
        "################################################################################\n",
        "# Deciding 40 %  of n for negative numbers for α rest of which was choosen     #\n",
        "# as Positive                                                                  #\n",
        "################################################################################\n",
        "\n",
        "(n1)= n*.4\n",
        "n1=math.floor(n*(.4))\n",
        "n2=math.floor(n-n1)\n",
        "\n",
        "alpha1=np.random.randint(-100, -1, (n1, 1))\n",
        "#print(alpha1)\n",
        "alpha2=np.random.randint(1, 100, (n2, 1))\n",
        "#print(alpha2)\n",
        "\n",
        "alpha1=alpha1/100\n",
        "alpha2=alpha2/100\n",
        "\n",
        "alpha=np.concatenate([alpha1,alpha2])\n",
        "print(\"Values of Alpha are:\\n\", alpha)\n",
        "\n",
        "############This would work for 1000 as well but for simplicity reduced it#####\n",
        "\n",
        "#x = np.random.randint(1, 1000, (n, 1))\n",
        "x = np.random.randint(1, 10, (n, 1))\n",
        "print(\"Values of x are:\\n\", x)\n",
        "\n",
        "print(\"len of x\",len(x))\n",
        "print(\"len of alpha\",len(alpha))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj_eGzbUMggD",
        "outputId": "9a905b20-18bb-4d60-ee94-51dcb604d72d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values of Alpha are:\n",
            " [[-0.63]\n",
            " [-0.77]\n",
            " [-0.27]\n",
            " [-0.77]\n",
            " [-0.35]\n",
            " [-0.77]\n",
            " [-0.92]\n",
            " [-0.18]\n",
            " [-0.77]\n",
            " [-0.59]\n",
            " [-0.1 ]\n",
            " [-0.2 ]\n",
            " [-0.81]\n",
            " [-0.6 ]\n",
            " [-0.03]\n",
            " [-0.13]\n",
            " [-0.58]\n",
            " [-0.08]\n",
            " [-0.31]\n",
            " [-0.73]\n",
            " [-0.26]\n",
            " [-0.4 ]\n",
            " [-0.34]\n",
            " [-0.64]\n",
            " [-1.  ]\n",
            " [-0.95]\n",
            " [-0.86]\n",
            " [-0.39]\n",
            " [-0.28]\n",
            " [-0.89]\n",
            " [-0.98]\n",
            " [-1.  ]\n",
            " [-0.31]\n",
            " [-0.89]\n",
            " [-0.61]\n",
            " [-0.16]\n",
            " [-0.82]\n",
            " [-0.08]\n",
            " [-0.76]\n",
            " [-0.44]\n",
            " [-0.47]\n",
            " [-0.19]\n",
            " [-0.92]\n",
            " [-0.57]\n",
            " [-0.74]\n",
            " [-0.41]\n",
            " [-0.62]\n",
            " [ 0.08]\n",
            " [ 0.47]\n",
            " [ 0.8 ]\n",
            " [ 0.55]\n",
            " [ 0.03]\n",
            " [ 0.84]\n",
            " [ 0.53]\n",
            " [ 0.6 ]\n",
            " [ 0.09]\n",
            " [ 0.99]\n",
            " [ 0.69]\n",
            " [ 0.18]\n",
            " [ 0.69]\n",
            " [ 0.05]\n",
            " [ 0.44]\n",
            " [ 0.78]\n",
            " [ 0.43]\n",
            " [ 0.28]\n",
            " [ 0.59]\n",
            " [ 0.26]\n",
            " [ 0.01]\n",
            " [ 0.93]\n",
            " [ 0.22]\n",
            " [ 0.36]\n",
            " [ 0.76]\n",
            " [ 0.54]\n",
            " [ 0.47]\n",
            " [ 0.55]\n",
            " [ 0.11]\n",
            " [ 0.64]\n",
            " [ 0.07]\n",
            " [ 0.36]\n",
            " [ 0.85]\n",
            " [ 0.06]\n",
            " [ 0.25]\n",
            " [ 0.99]\n",
            " [ 0.94]\n",
            " [ 0.67]\n",
            " [ 0.76]\n",
            " [ 0.54]\n",
            " [ 0.07]\n",
            " [ 0.35]\n",
            " [ 0.71]\n",
            " [ 0.18]\n",
            " [ 0.87]\n",
            " [ 0.73]\n",
            " [ 0.35]\n",
            " [ 0.8 ]\n",
            " [ 0.83]\n",
            " [ 0.04]\n",
            " [ 0.14]\n",
            " [ 0.77]\n",
            " [ 0.39]\n",
            " [ 0.18]\n",
            " [ 0.4 ]\n",
            " [ 0.75]\n",
            " [ 0.53]\n",
            " [ 0.77]\n",
            " [ 0.29]\n",
            " [ 0.33]\n",
            " [ 0.15]\n",
            " [ 0.02]\n",
            " [ 0.23]\n",
            " [ 0.75]\n",
            " [ 0.61]\n",
            " [ 0.49]\n",
            " [ 0.9 ]\n",
            " [ 0.59]\n",
            " [ 0.43]\n",
            " [ 0.12]\n",
            " [ 0.93]]\n",
            "Values of x are:\n",
            " [[5]\n",
            " [2]\n",
            " [6]\n",
            " [2]\n",
            " [6]\n",
            " [1]\n",
            " [7]\n",
            " [3]\n",
            " [9]\n",
            " [7]\n",
            " [9]\n",
            " [3]\n",
            " [9]\n",
            " [9]\n",
            " [5]\n",
            " [7]\n",
            " [6]\n",
            " [1]\n",
            " [2]\n",
            " [4]\n",
            " [2]\n",
            " [5]\n",
            " [7]\n",
            " [6]\n",
            " [4]\n",
            " [4]\n",
            " [2]\n",
            " [6]\n",
            " [1]\n",
            " [7]\n",
            " [1]\n",
            " [8]\n",
            " [4]\n",
            " [7]\n",
            " [9]\n",
            " [7]\n",
            " [6]\n",
            " [2]\n",
            " [7]\n",
            " [8]\n",
            " [7]\n",
            " [3]\n",
            " [1]\n",
            " [1]\n",
            " [4]\n",
            " [5]\n",
            " [9]\n",
            " [8]\n",
            " [3]\n",
            " [5]\n",
            " [5]\n",
            " [8]\n",
            " [8]\n",
            " [6]\n",
            " [6]\n",
            " [3]\n",
            " [5]\n",
            " [6]\n",
            " [8]\n",
            " [9]\n",
            " [7]\n",
            " [9]\n",
            " [2]\n",
            " [1]\n",
            " [9]\n",
            " [7]\n",
            " [8]\n",
            " [3]\n",
            " [8]\n",
            " [5]\n",
            " [8]\n",
            " [1]\n",
            " [8]\n",
            " [4]\n",
            " [6]\n",
            " [4]\n",
            " [6]\n",
            " [2]\n",
            " [3]\n",
            " [9]\n",
            " [9]\n",
            " [5]\n",
            " [1]\n",
            " [4]\n",
            " [2]\n",
            " [3]\n",
            " [1]\n",
            " [5]\n",
            " [3]\n",
            " [9]\n",
            " [8]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [7]\n",
            " [9]\n",
            " [6]\n",
            " [3]\n",
            " [5]\n",
            " [1]\n",
            " [4]\n",
            " [9]\n",
            " [9]\n",
            " [6]\n",
            " [9]\n",
            " [9]\n",
            " [8]\n",
            " [6]\n",
            " [7]\n",
            " [3]\n",
            " [6]\n",
            " [3]\n",
            " [8]\n",
            " [5]\n",
            " [2]\n",
            " [5]\n",
            " [9]\n",
            " [7]]\n",
            "len of x 118\n",
            "len of alpha 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#        INITIAL VALUES FOR VARIABLES TO BE USED IN GRADIENT DESCENT           #\n",
        "################################################################################\n",
        "valX = x                     # Initial Value of x is set here\n",
        "iterations = 0                  # Initialize iteration\n",
        "tolerance = 2/100               # Tolerance was set as 2%\n",
        "printData = True                # Helps to exit loop\n",
        "maxIterations = 10000            # Number of Iterations\n",
        "al=alpha                        # α\n",
        "tempvalX=0                      # Temporary Value\n",
        "eta=0.01                        #Learning Rate η\n",
        "fun=0\n",
        "getout=0\n",
        "\n",
        "initvalXfn = 0\n",
        "initvalX=x\n",
        "\n",
        "for i in range(0,n):\n",
        "      initvalXfn = initvalX[i] + initvalXfn\n",
        "\n",
        "print(\"Initial x = \"+str(initvalXfn)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "  fn=[]\n",
        "  tempvalX=[]\n",
        "  x=[]\n",
        "  \n",
        "  for i in range(0,n):\n",
        "          fn.append(fun)\n",
        "          tempvalX.append(fun)\n",
        "          x.append(fun)\n",
        "\n",
        "#  if iterations < 3:\n",
        "#      print(\"iterations num\",iterations)\n",
        "#      print(\"valX\",valX)\n",
        "\n",
        "  for i in range(0,n):\n",
        "          x[i]=valX[i]\n",
        "          fn[i]=(2*x[i]*al[i]) + fn[i]\n",
        "          fn[i] = fn[i] * eta\n",
        "\n",
        "#  if iterations < 3:\n",
        "#      print(\"iterations num\",iterations)\n",
        "#      print(\"x[i]\",x)\n",
        "#      print(\"al[i]\",al)\n",
        "\n",
        "  for i in range(0,n):\n",
        "          fn[i] = fn[i] * eta\n",
        "\n",
        "  for i in range(0,n):\n",
        "          tempvalX[i] = math.floor(valX[i] - fn[i])\n",
        "  \n",
        "#  if iterations < 3:\n",
        "#      print(\"fn[i]\",fn)\n",
        "\n",
        "  tempvalXfn = 0\n",
        "  valXfn = 0\n",
        "\n",
        "  for i in range(0,n):\n",
        "    tempvalXfn = tempvalX[i] + tempvalXfn\n",
        "    valXfn = valX[i] + valXfn\n",
        "\n",
        " #         if abs(tempvalX[i]-valX[i]) < tolerance:\n",
        " #           getout=1\n",
        "          \n",
        "          #if abs(tempvalX[i]-valX[i]) < tolerance:\n",
        "  if abs(tempvalXfn-valXfn) < tolerance:\n",
        "        break  \n",
        "\n",
        "\n",
        "\n",
        "  iterations += 1\n",
        "\n",
        "  if iterations > maxIterations:\n",
        "    print(\"Too many iterations. Adjust alpha and make sure that the function is convex!\")\n",
        "    printData = False\n",
        "    break\n",
        "  \n",
        "              \n",
        "\n",
        "  print(\"x = \"+str(tempvalXfn)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "  #Update the values for next iteration\n",
        "  for i in range(0,n):\n",
        "      valX[i] = tempvalX[i]\n",
        "\n",
        "if printData:\n",
        "# print(\"The function at value \"+str(fn)+\" converges to a minimum\")\n",
        " print(\"Number of iterations:\",iterations,sep=\" \")\n",
        " print(\"Final x =\",tempvalX,sep=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zNLHtMOq5NT",
        "outputId": "560d763c-208d-46b3-f9d8-33370b5b284b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial x = [631] Iteration = 0\n",
            "x = 560 Iteration = 1\n",
            "x = 494 Iteration = 2\n",
            "x = 433 Iteration = 3\n",
            "x = 382 Iteration = 4\n",
            "x = 336 Iteration = 5\n",
            "x = 299 Iteration = 6\n",
            "x = 271 Iteration = 7\n",
            "x = 248 Iteration = 8\n",
            "x = 236 Iteration = 9\n",
            "Number of iterations: 9\n",
            "Final x = [5, 2, 6, 2, 6, 1, 7, 3, 9, 7, 9, 3, 9, 9, 5, 7, 6, 1, 2, 4, 2, 5, 7, 6, 4, 4, 2, 6, 1, 7, 1, 8, 4, 7, 9, 7, 6, 2, 7, 8, 7, 3, 1, 1, 4, 5, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    }
  ]
}