{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1VEdQlmIeOni7zAqb0PDI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthikeyan-ganesan86/CS/blob/master/Gradient_Descent_Implementation_Different_X_values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#**************************************************************************#\n",
        "#Import all libraries for using in the program                             # \n",
        "#**************************************************************************#\n",
        "# DESCRIPTION: IMPLEMENTING GRADIENT DESCENT                               #\n",
        "#--------------------------------------------------------------------------#\n",
        "#           Name       BITS ID                                             #\n",
        "#--------------------------------------------------------------------------#\n",
        "#      Karthikeyan G  ***********                                          #\n",
        "#--------------------------------------------------------------------------#\n",
        "############################################################################\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from sympy import *\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "################################################################################\n",
        "#Random Number for n is choosen between 75 and 140                             #\n",
        "################################################################################\n",
        "\n",
        "n = random.randint(75, 140)\n",
        "\n",
        "################################################################################\n",
        "# Deciding 40 %  of n for negative numbers for Î± rest of which was choosen     #\n",
        "# as Positive                                                                  #\n",
        "################################################################################\n",
        "\n",
        "(n1)= n*.4\n",
        "n1=math.floor(n*(.4))\n",
        "n2=math.floor(n-n1)\n",
        "\n",
        "alpha1=np.random.randint(-100, -1, (n1, 1))\n",
        "#print(alpha1)\n",
        "alpha2=np.random.randint(1, 100, (n2, 1))\n",
        "#print(alpha2)\n",
        "\n",
        "alpha1=alpha1/100\n",
        "alpha2=alpha2/100\n",
        "\n",
        "alpha=np.concatenate([alpha1,alpha2])\n",
        "print(\"Values of Alpha are:\\n\", alpha)\n",
        "\n",
        "############This would work for 1000 as well but for simplicity reduced it#####\n",
        "\n",
        "#x = np.random.randint(1, 1000, (n, 1))\n",
        "x = np.random.randint(1, 10, (n, 1))\n",
        "print(\"Values of x are:\\n\", x)\n",
        "\n",
        "print(\"len of x\",len(x))\n",
        "print(\"len of alpha\",len(alpha))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj_eGzbUMggD",
        "outputId": "7ff01466-ef78-48aa-ed77-53702ff31ccb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values of Alpha are:\n",
            " [[-0.82]\n",
            " [-0.61]\n",
            " [-0.52]\n",
            " [-0.99]\n",
            " [-0.41]\n",
            " [-0.87]\n",
            " [-0.75]\n",
            " [-0.61]\n",
            " [-0.12]\n",
            " [-0.72]\n",
            " [-0.71]\n",
            " [-0.05]\n",
            " [-0.4 ]\n",
            " [-0.03]\n",
            " [-0.66]\n",
            " [-0.79]\n",
            " [-0.65]\n",
            " [-0.23]\n",
            " [-0.26]\n",
            " [-0.71]\n",
            " [-0.46]\n",
            " [-0.93]\n",
            " [-0.19]\n",
            " [-0.3 ]\n",
            " [-0.07]\n",
            " [-0.29]\n",
            " [-0.71]\n",
            " [-0.46]\n",
            " [-0.78]\n",
            " [-0.8 ]\n",
            " [-0.11]\n",
            " [-0.19]\n",
            " [-0.51]\n",
            " [-0.67]\n",
            " [-0.8 ]\n",
            " [-0.11]\n",
            " [-0.48]\n",
            " [-0.65]\n",
            " [-0.28]\n",
            " [-0.24]\n",
            " [-0.16]\n",
            " [-0.58]\n",
            " [-0.12]\n",
            " [-0.83]\n",
            " [-0.54]\n",
            " [-0.5 ]\n",
            " [-0.81]\n",
            " [-0.58]\n",
            " [-0.04]\n",
            " [-0.93]\n",
            " [-0.38]\n",
            " [-0.79]\n",
            " [-0.15]\n",
            " [-0.04]\n",
            " [-0.56]\n",
            " [ 0.01]\n",
            " [ 0.57]\n",
            " [ 0.64]\n",
            " [ 0.09]\n",
            " [ 0.03]\n",
            " [ 0.77]\n",
            " [ 0.37]\n",
            " [ 0.51]\n",
            " [ 0.37]\n",
            " [ 0.71]\n",
            " [ 0.25]\n",
            " [ 0.67]\n",
            " [ 0.72]\n",
            " [ 0.94]\n",
            " [ 0.07]\n",
            " [ 0.42]\n",
            " [ 0.98]\n",
            " [ 0.31]\n",
            " [ 0.2 ]\n",
            " [ 0.42]\n",
            " [ 0.13]\n",
            " [ 0.67]\n",
            " [ 0.29]\n",
            " [ 0.77]\n",
            " [ 0.15]\n",
            " [ 0.27]\n",
            " [ 0.01]\n",
            " [ 0.98]\n",
            " [ 0.11]\n",
            " [ 0.88]\n",
            " [ 0.95]\n",
            " [ 0.27]\n",
            " [ 0.67]\n",
            " [ 0.66]\n",
            " [ 0.8 ]\n",
            " [ 0.56]\n",
            " [ 0.04]\n",
            " [ 0.37]\n",
            " [ 0.03]\n",
            " [ 0.13]\n",
            " [ 0.96]\n",
            " [ 0.26]\n",
            " [ 0.3 ]\n",
            " [ 0.69]\n",
            " [ 0.34]\n",
            " [ 0.28]\n",
            " [ 0.93]\n",
            " [ 0.76]\n",
            " [ 0.94]\n",
            " [ 0.76]\n",
            " [ 0.75]\n",
            " [ 0.66]\n",
            " [ 0.98]\n",
            " [ 0.45]\n",
            " [ 0.94]\n",
            " [ 0.45]\n",
            " [ 0.85]\n",
            " [ 0.44]\n",
            " [ 0.11]\n",
            " [ 0.53]\n",
            " [ 0.77]\n",
            " [ 0.17]\n",
            " [ 0.45]\n",
            " [ 0.16]\n",
            " [ 0.98]\n",
            " [ 0.96]\n",
            " [ 0.79]\n",
            " [ 0.63]\n",
            " [ 0.38]\n",
            " [ 0.7 ]\n",
            " [ 0.15]\n",
            " [ 0.57]\n",
            " [ 0.59]\n",
            " [ 0.07]\n",
            " [ 0.55]\n",
            " [ 0.49]\n",
            " [ 0.48]\n",
            " [ 0.62]\n",
            " [ 0.43]\n",
            " [ 0.12]\n",
            " [ 0.88]\n",
            " [ 0.71]\n",
            " [ 0.08]]\n",
            "Values of x are:\n",
            " [[2]\n",
            " [3]\n",
            " [9]\n",
            " [4]\n",
            " [4]\n",
            " [5]\n",
            " [1]\n",
            " [3]\n",
            " [5]\n",
            " [2]\n",
            " [2]\n",
            " [7]\n",
            " [2]\n",
            " [1]\n",
            " [5]\n",
            " [6]\n",
            " [6]\n",
            " [8]\n",
            " [4]\n",
            " [1]\n",
            " [9]\n",
            " [7]\n",
            " [3]\n",
            " [2]\n",
            " [8]\n",
            " [6]\n",
            " [5]\n",
            " [9]\n",
            " [5]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [9]\n",
            " [6]\n",
            " [5]\n",
            " [9]\n",
            " [1]\n",
            " [6]\n",
            " [3]\n",
            " [8]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [9]\n",
            " [8]\n",
            " [8]\n",
            " [9]\n",
            " [1]\n",
            " [4]\n",
            " [4]\n",
            " [1]\n",
            " [6]\n",
            " [7]\n",
            " [1]\n",
            " [4]\n",
            " [9]\n",
            " [8]\n",
            " [7]\n",
            " [7]\n",
            " [9]\n",
            " [5]\n",
            " [2]\n",
            " [4]\n",
            " [4]\n",
            " [6]\n",
            " [2]\n",
            " [1]\n",
            " [7]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [5]\n",
            " [6]\n",
            " [3]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [4]\n",
            " [8]\n",
            " [3]\n",
            " [4]\n",
            " [7]\n",
            " [1]\n",
            " [7]\n",
            " [5]\n",
            " [9]\n",
            " [2]\n",
            " [8]\n",
            " [5]\n",
            " [5]\n",
            " [7]\n",
            " [1]\n",
            " [1]\n",
            " [4]\n",
            " [7]\n",
            " [5]\n",
            " [4]\n",
            " [7]\n",
            " [8]\n",
            " [5]\n",
            " [8]\n",
            " [6]\n",
            " [8]\n",
            " [7]\n",
            " [4]\n",
            " [7]\n",
            " [1]\n",
            " [7]\n",
            " [8]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [7]\n",
            " [4]\n",
            " [4]\n",
            " [9]\n",
            " [3]\n",
            " [6]\n",
            " [7]\n",
            " [5]\n",
            " [9]\n",
            " [6]\n",
            " [5]\n",
            " [3]\n",
            " [9]\n",
            " [4]\n",
            " [1]\n",
            " [4]\n",
            " [8]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [8]]\n",
            "len of x 138\n",
            "len of alpha 138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#        INITIAL VALUES FOR VARIABLES TO BE USED IN GRADIENT DESCENT           #\n",
        "################################################################################\n",
        "valX = x                     # Initial Value of x is set here\n",
        "iterations = 0                  # Initialize iteration\n",
        "tolerance = 2/100               # Tolerance was set as 2%\n",
        "printData = True                # Helps to exit loop\n",
        "maxIterations = 10000            # Number of Iterations\n",
        "al=alpha                        # Î±\n",
        "tempvalX=0                      # Temporary Value\n",
        "eta=0.01                        #Learning Rate Î·\n",
        "fun=0\n",
        "getout=0\n",
        "\n",
        "initvalXfn = 0\n",
        "initvalX=x\n",
        "\n",
        "for i in range(0,n):\n",
        "      initvalXfn = initvalX[i] + initvalXfn\n",
        "\n",
        "print(\"Initial x = \"+str(initvalXfn)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "  fn=[]\n",
        "  tempvalX=[]\n",
        "  x=[]\n",
        "  \n",
        "  for i in range(0,n):\n",
        "          fn.append(fun)\n",
        "          tempvalX.append(fun)\n",
        "          x.append(fun)\n",
        "\n",
        "#  if iterations < 3:\n",
        "#      print(\"iterations num\",iterations)\n",
        "#      print(\"valX\",valX)\n",
        "\n",
        "  for i in range(0,n):\n",
        "          x[i]=valX[i]\n",
        "          fn[i]=(2*x[i]*al[i]) + fn[i]\n",
        "          fn[i] = fn[i] * eta\n",
        "\n",
        "#  if iterations < 3:\n",
        "#      print(\"iterations num\",iterations)\n",
        "#      print(\"x[i]\",x)\n",
        "#      print(\"al[i]\",al)\n",
        "\n",
        "  for i in range(0,n):\n",
        "          fn[i] = fn[i] * eta\n",
        "\n",
        "  for i in range(0,n):\n",
        "          tempvalX[i] = math.floor(valX[i] - fn[i])\n",
        "  \n",
        "#  if iterations < 3:\n",
        "#      print(\"fn[i]\",fn)\n",
        "\n",
        "  tempvalXfn = 0\n",
        "  valXfn = 0\n",
        "\n",
        "  for i in range(0,n):\n",
        "    tempvalXfn = tempvalX[i] + tempvalXfn\n",
        "    valXfn = valX[i] + valXfn\n",
        "\n",
        " #         if abs(tempvalX[i]-valX[i]) < tolerance:\n",
        " #           getout=1\n",
        "          \n",
        "          #if abs(tempvalX[i]-valX[i]) < tolerance:\n",
        "  if abs(tempvalXfn-valXfn) < tolerance:\n",
        "        break  \n",
        "\n",
        "\n",
        "\n",
        "  iterations += 1\n",
        "\n",
        "  if iterations > maxIterations:\n",
        "    print(\"Too many iterations. Adjust alpha and make sure that the function is convex!\")\n",
        "    printData = False\n",
        "    break\n",
        "  \n",
        "              \n",
        "\n",
        "  print(\"x = \"+str(tempvalXfn)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "  #Update the values for next iteration\n",
        "  for i in range(0,n):\n",
        "      valX[i] = tempvalX[i]\n",
        "\n",
        "tempvalXfn = 0\n",
        "valXfn = 0\n",
        "\n",
        "for i in range(0,n):\n",
        "   tempvalXfn = tempvalX[i] + tempvalXfn\n",
        "\n",
        "if printData:\n",
        " print(\"It converges at minimum at \"+str(tempvalXfn))\n",
        " print(\"Number of iterations:\",iterations,sep=\" \")\n",
        " print(\"Final x =\",tempvalX,sep=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zNLHtMOq5NT",
        "outputId": "2f68b01d-4397-46be-87c2-86140a825324"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial x = [664] Iteration = 0\n",
            "x = 581 Iteration = 1\n",
            "x = 506 Iteration = 2\n",
            "x = 438 Iteration = 3\n",
            "x = 380 Iteration = 4\n",
            "x = 338 Iteration = 5\n",
            "x = 305 Iteration = 6\n",
            "x = 277 Iteration = 7\n",
            "x = 262 Iteration = 8\n",
            "x = 256 Iteration = 9\n",
            "It converges at minimum at 256\n",
            "Number of iterations: 9\n",
            "Final x = [2, 3, 9, 4, 4, 5, 1, 3, 5, 2, 2, 7, 2, 1, 5, 6, 6, 8, 4, 1, 9, 7, 3, 2, 8, 6, 5, 9, 5, 2, 1, 1, 9, 6, 5, 9, 1, 6, 3, 8, 3, 2, 2, 3, 4, 9, 8, 8, 9, 1, 4, 4, 1, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    }
  ]
}