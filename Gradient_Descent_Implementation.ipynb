{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlQQgHdMT9xfKyx9osXbKT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthikeyan-ganesan86/CS/blob/master/Gradient_Descent_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#**************************************************************************#\n",
        "#Import all libraries for using in the program                             # \n",
        "#**************************************************************************#\n",
        "# DESCRIPTION: IMPLEMENTING GRADIENT DESCENT                               #\n",
        "#--------------------------------------------------------------------------#\n",
        "#           Name       BITS ID                                             #\n",
        "#--------------------------------------------------------------------------#\n",
        "#      Karthikeyan G  ***********                                          #\n",
        "#--------------------------------------------------------------------------#\n",
        "############################################################################\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from sympy import *\n",
        "\n",
        "\n",
        "################################################################################\n",
        "#Random Number for n is choosen between 75 and 140                             #\n",
        "################################################################################\n",
        "\n",
        "n = random.randint(75, 140)\n",
        "\n",
        "################################################################################\n",
        "# Deciding 40 %  of n for negative numbers for α rest of which was choosen     #\n",
        "# as Positive                                                                  #\n",
        "################################################################################\n",
        "\n",
        "(n1)= n*.4\n",
        "n1=math.floor(n*(.4))\n",
        "n2=math.floor(n-n1)\n",
        "\n",
        "alpha1=np.random.randint(-100, -1, (n1, 1))\n",
        "#print(alpha1)\n",
        "alpha2=np.random.randint(1, 100, (n2, 1))\n",
        "#print(alpha2)\n",
        "\n",
        "alpha1=alpha1/100\n",
        "alpha2=alpha2/100\n",
        "\n",
        "alpha=np.concatenate([alpha1,alpha2])\n",
        "print(\"Values of Alpha are:\\n\", alpha)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj_eGzbUMggD",
        "outputId": "cce931a5-d699-4208-844e-8dadfcb0ad29"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values of Alpha are:\n",
            " [[-0.55]\n",
            " [-0.9 ]\n",
            " [-0.75]\n",
            " [-0.39]\n",
            " [-0.08]\n",
            " [-0.81]\n",
            " [-0.82]\n",
            " [-0.22]\n",
            " [-0.21]\n",
            " [-0.43]\n",
            " [-0.62]\n",
            " [-0.75]\n",
            " [-0.73]\n",
            " [-0.58]\n",
            " [-0.81]\n",
            " [-0.37]\n",
            " [-0.42]\n",
            " [-0.59]\n",
            " [-0.15]\n",
            " [-0.67]\n",
            " [-1.  ]\n",
            " [-0.46]\n",
            " [-0.84]\n",
            " [-0.95]\n",
            " [-0.11]\n",
            " [-0.41]\n",
            " [-0.97]\n",
            " [-1.  ]\n",
            " [-0.16]\n",
            " [-0.32]\n",
            " [-0.41]\n",
            " [-0.13]\n",
            " [-0.81]\n",
            " [-0.67]\n",
            " [-0.66]\n",
            " [-0.47]\n",
            " [-0.21]\n",
            " [-0.84]\n",
            " [-0.37]\n",
            " [-0.25]\n",
            " [-0.34]\n",
            " [-0.11]\n",
            " [-0.72]\n",
            " [-0.9 ]\n",
            " [-0.67]\n",
            " [-0.89]\n",
            " [-0.26]\n",
            " [ 0.88]\n",
            " [ 0.44]\n",
            " [ 0.01]\n",
            " [ 0.88]\n",
            " [ 0.84]\n",
            " [ 0.58]\n",
            " [ 0.46]\n",
            " [ 0.8 ]\n",
            " [ 0.73]\n",
            " [ 0.75]\n",
            " [ 0.58]\n",
            " [ 0.36]\n",
            " [ 0.46]\n",
            " [ 0.01]\n",
            " [ 0.31]\n",
            " [ 0.4 ]\n",
            " [ 0.27]\n",
            " [ 0.85]\n",
            " [ 0.5 ]\n",
            " [ 0.07]\n",
            " [ 0.69]\n",
            " [ 0.71]\n",
            " [ 0.97]\n",
            " [ 0.43]\n",
            " [ 0.41]\n",
            " [ 0.84]\n",
            " [ 0.02]\n",
            " [ 0.41]\n",
            " [ 0.39]\n",
            " [ 0.94]\n",
            " [ 0.85]\n",
            " [ 0.97]\n",
            " [ 0.9 ]\n",
            " [ 0.13]\n",
            " [ 0.17]\n",
            " [ 0.74]\n",
            " [ 0.64]\n",
            " [ 0.76]\n",
            " [ 0.18]\n",
            " [ 0.54]\n",
            " [ 0.32]\n",
            " [ 0.15]\n",
            " [ 0.47]\n",
            " [ 0.28]\n",
            " [ 0.59]\n",
            " [ 0.01]\n",
            " [ 0.6 ]\n",
            " [ 0.86]\n",
            " [ 0.91]\n",
            " [ 0.06]\n",
            " [ 0.02]\n",
            " [ 0.08]\n",
            " [ 0.63]\n",
            " [ 0.94]\n",
            " [ 0.77]\n",
            " [ 0.31]\n",
            " [ 0.6 ]\n",
            " [ 0.56]\n",
            " [ 0.16]\n",
            " [ 0.18]\n",
            " [ 0.32]\n",
            " [ 0.92]\n",
            " [ 0.1 ]\n",
            " [ 0.03]\n",
            " [ 0.33]\n",
            " [ 0.7 ]\n",
            " [ 0.17]\n",
            " [ 0.49]\n",
            " [ 0.43]\n",
            " [ 0.51]\n",
            " [ 0.46]\n",
            " [ 0.21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#        INITIAL VALUES FOR VARIABLES TO BE USED IN GRADIENT DESCENT           #\n",
        "################################################################################\n",
        "valX = 1000                     # Initial Value of x is set here\n",
        "iterations = 0                  # Initialize iteration\n",
        "tolerance = 2/100               # Tolerance was set as 2%\n",
        "printData = True                # Helps to exit loop\n",
        "maxIterations = 1000            # Number of Iterations\n",
        "al=alpha                        # α\n",
        "tempvalX=0                      # Temporary Value\n",
        "eta=0.01                        #Learning Rate η\n",
        "\n",
        "\n",
        "print(\"Initial x = \"+str(valX)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "while True:\n",
        "\n",
        "################################################################################\n",
        "# Derivative of (Σ αᵢXᵢ²) is (2 * xᵢ * αᵢ) this is added n times from 1 to n   #\n",
        "# Substituting the value if xᵢ initially as 1000 and αᵢ randomly chosen above  #\n",
        "################################################################################\n",
        "\n",
        "  fn=0\n",
        "  x=[]\n",
        "  \n",
        "  for i in range(0,n):\n",
        "    x.append(valX)\n",
        "    fn=(2*x[i]*al[i]) + fn\n",
        "\n",
        "################################################################################\n",
        "# fn is multiplied by multiplied with learning rate 0.01   #Learning Rate η    #\n",
        "################################################################################\n",
        "\n",
        "  fn = fn * eta\n",
        "\n",
        "#  print(\"valX before\",valX)\n",
        "#  print(\"tempvalX before\",valX - fn)\n",
        "  tempvalX=  math.ceil(valX - fn)\n",
        "#  print(\"tempvalX after\",tempvalX)\n",
        "\n",
        "  if abs(tempvalX-valX) < tolerance:\n",
        "    break\n",
        "\n",
        "  #If the number of iterations goes out of bounds, maybe valX (and/or valY) is diverging\n",
        "  #Let's stop the loop and try to understand.\n",
        "   \n",
        "  iterations += 1\n",
        "  if iterations > maxIterations:\n",
        "     print(\"Too many iterations. Adjust alpha and make sure that the function is convex!\")\n",
        "     printData = False\n",
        "     break\n",
        "  \n",
        "  #print(\"tempvalX before\",tempvalX)\n",
        "  #tempvalX=(math.ceil(tempvalX))\n",
        "  #print(\"tempvalX after\",tempvalX)\n",
        "  #print(\"valX\",valX)\n",
        "\n",
        "#  if abs(tempvalX-valX) < tolerance:\n",
        "#    break\n",
        "    \n",
        "  print(\"x = \"+str(tempvalX)+\" Iteration =\",iterations)\n",
        "\n",
        "\n",
        "  #Update the values for next iteration\n",
        "  valX = tempvalX\n",
        "\n",
        "if printData:\n",
        " print(\"It converges to minimum at value \"+str(tempvalX))\n",
        " print(\"Number of iterations:\",iterations,sep=\" \")\n",
        "# print(\"Final x =\",tempvalX,sep=\" \")\n",
        "\n",
        "\n",
        "#print(valX-fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lgn_O9SqdXi",
        "outputId": "6fde1712-3831-4efc-91a4-84a96c61b2e9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial x = 1000 Iteration = 0\n",
            "x = 815 Iteration = 1\n",
            "x = 665 Iteration = 2\n",
            "x = 542 Iteration = 3\n",
            "x = 442 Iteration = 4\n",
            "x = 361 Iteration = 5\n",
            "x = 295 Iteration = 6\n",
            "x = 241 Iteration = 7\n",
            "x = 197 Iteration = 8\n",
            "x = 161 Iteration = 9\n",
            "x = 132 Iteration = 10\n",
            "x = 108 Iteration = 11\n",
            "x = 88 Iteration = 12\n",
            "x = 72 Iteration = 13\n",
            "x = 59 Iteration = 14\n",
            "x = 49 Iteration = 15\n",
            "x = 40 Iteration = 16\n",
            "x = 33 Iteration = 17\n",
            "x = 27 Iteration = 18\n",
            "x = 22 Iteration = 19\n",
            "x = 18 Iteration = 20\n",
            "x = 15 Iteration = 21\n",
            "x = 13 Iteration = 22\n",
            "x = 11 Iteration = 23\n",
            "x = 9 Iteration = 24\n",
            "x = 8 Iteration = 25\n",
            "x = 7 Iteration = 26\n",
            "x = 6 Iteration = 27\n",
            "x = 5 Iteration = 28\n",
            "It converges to minimum at value 5\n",
            "Number of iterations: 28\n"
          ]
        }
      ]
    }
  ]
}